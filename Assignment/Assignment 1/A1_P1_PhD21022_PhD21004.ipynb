{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7684a2e2",
   "metadata": {},
   "source": [
    "CSE641 - Deep Learning - Assignment 1\n",
    "\n",
    "PART I: Perceptron Training Algorithm\n",
    "\n",
    "@author: Shyama Sastha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d97b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae21a7",
   "metadata": {},
   "source": [
    "### Implementation of PTA for AND, OR and NOT gates\n",
    "#### Points to be noted:\n",
    "    # The iterations will be much less when the learning rate is set to 1.\n",
    "    # The reason for not setting the learning rate to 1 is to find the bound\n",
    "    # Cannot compute bound equation if w2 becomes 0 due to divide by zero error\n",
    "    # It can be seen from the XOR graphs that after a few tries, the perceptron gives up and assumes two boundaries instead of a single bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f72c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step function for prediction\n",
    "def prediction(y_hat):\n",
    "  if y_hat >= 0:\n",
    "    return 1\n",
    "  else:\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2363385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for errors in the iteration\n",
    "def errorcheck(error):\n",
    "    if 1 in error:\n",
    "        E = 1\n",
    "    else:\n",
    "        E = 0\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0053a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision boundary line is given by x1w1 + x2w2 + b = 0\n",
    "# Reforming this equation to get x2 = -(x1w1 + b)/w2 as boundary function\n",
    "def bound(x1, w1, b, w2):\n",
    "    if w2 != 0:\n",
    "        return (-1 * ((x1 * w1) + b)/w2)\n",
    "    else:\n",
    "        return (-1 * ((x1 * w1) + b))\n",
    "\n",
    "# Decision point is given by x1w1 + b = 0\n",
    "# Reforming this equation to get x1 = -b/w1 as predicted point\n",
    "def boundN(w1, b):\n",
    "    if w1 != 0:\n",
    "        return (-1 * b/w1)\n",
    "    else:\n",
    "        return (-1 * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9fddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the plot function for 2 inputs\n",
    "def plotbound(X1, X2, pp, y, cc, tt):\n",
    "    c = np.array(y)\n",
    "    c[c == -1] = 0\n",
    "    xp, yp = x.T\n",
    "    colormap = np.array(['r', 'g'])\n",
    "    plt.scatter(xp, yp, s=20, c=colormap[c])\n",
    "    plt.plot(X1,X2, color=cc)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.title(tt)\n",
    "    plt.savefig(pp, format='pdf')\n",
    "\n",
    "# Defining the plot function for 1 input\n",
    "def plotboundN(X1, y, pp, cc, tt):\n",
    "    plt.plot(0, 0, marker=\"o\", markersize=5, color=\"g\")\n",
    "    plt.plot(1, 1, marker=\"o\", markersize=5, color=\"r\")\n",
    "    plt.plot(X1, y, color=cc)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('b')\n",
    "    plt.title(tt)\n",
    "    plt.savefig(pp, format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3159b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to train the perceptron and plot the boundaries\n",
    "def train(x, y, pp, G):\n",
    "    \"\"\"\n",
    "    # Initialize random values of weights for w1 and w2\n",
    "    w = np.random.randint(3, size=(1, 3))\n",
    "    w1 = w[0][0]\n",
    "    w2 = w[0][1]\n",
    "    bias = w[0][2]\n",
    "    \"\"\"\n",
    "    # Initialize randomly chosen weights\n",
    "    w1 = 1\n",
    "    w2 = 1\n",
    "    bias = 1\n",
    "\n",
    "    # Find out the bound after the first iteration\n",
    "    X1 = [None] * 4\n",
    "    X2 = [None] * 4\n",
    "\n",
    "    for i in range(len(x)):\n",
    "            X1[i] = x[i][0]\n",
    "            X2[i] = bound(x[i][0], w1, bias, w2)\n",
    "\n",
    "    # Plotting the initial boundary\n",
    "    plotbound(X1, X2, pp, y, \"black\", \"Boundary after weights initialization\")\n",
    "\n",
    "    # The max number of iterations is given to make sure the loop exits\n",
    "    # The PTA runs till convergence for a linearly separable problem\n",
    "    max = 20\n",
    "    itr = 1\n",
    "    wandb = [[w1, w2, bias]]\n",
    "    error = np.array([1,1,1,1])\n",
    "    while itr < max and errorcheck(error):\n",
    "        for i in range(len(x)):\n",
    "            y_hat = prediction(np.dot(np.array([w1, w2]) , x[i])  + bias)\n",
    "            if y_hat != y[i]:\n",
    "                error[i] = 1\n",
    "                w1 = w1 + y[i] * x[i][0]\n",
    "                w2 = w2 + y[i] * x[i][1]\n",
    "                bias = bias + y[i]\n",
    "                itr = itr + 1\n",
    "                break\n",
    "            else:\n",
    "                error[i] = 0\n",
    "            X1[i] = x[i][0]\n",
    "            X2[i] = bound(x[i][0], w1, bias, w2)\n",
    "        plotbound(X1, X2, pp, y, \"black\", \"Boundary after updating weights\")\n",
    "    plotbound(X1, X2, pp, y, \"blue\", \"Boundary after perceptron\")\n",
    "    wandb.append([w1, w2, bias])\n",
    "    plt.clf()\n",
    "    if(G == \"XOR\"):\n",
    "        print(\"Nuumber of iterations before quiting for the {} PTA: {}\".format(G, itr+1))\n",
    "    else:\n",
    "        print(\"Final number of iterations for the {} PTA: {}\".format(G, itr+1))\n",
    "        print(\"Inital and Final weights & bias for the {} PTA: {}\".format(G, wandb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c9c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function for NOT gate\n",
    "def trainN(x, y, pp, G):\n",
    "    \"\"\"\n",
    "    # Initialize random values of weights for w1 and w2\n",
    "    w = np.random.randint(3, size=(1, 2))\n",
    "    w1 = w[0][0]\n",
    "    bias = w[0][1]\n",
    "    \"\"\"\n",
    "    # Initialize randomly chosen weights\n",
    "    w1 = 1\n",
    "    bias = 1\n",
    "\n",
    "    # Find out the bound of the first iteration\n",
    "    X1 = [None] * 2\n",
    "    error = np.array([0,0])\n",
    "    for i in range(len(x)):\n",
    "            X1[i] = boundN(w1, bias) + 0.5\n",
    "\n",
    "    # Plotting the initial prediction\n",
    "    plotboundN(X1, y, pp, \"black\", \"Boundary after weights initialization\")\n",
    "\n",
    "    # The max number of iterations is given to make sure the loop exits\n",
    "    # The PTA runs till convergence for a linearly separable problem\n",
    "    max = 10\n",
    "    itr = 1\n",
    "    wandb = [[w1, bias]]\n",
    "    error = np.array([1,1])\n",
    "    while itr < max and errorcheck(error):\n",
    "        for i in range(len(x)):\n",
    "            y_hat = prediction(np.dot(w1, x[i])  + bias)\n",
    "            if y_hat != y[i]:\n",
    "                error[i] = 1\n",
    "                w1 = w1 + y[i] * x[i]\n",
    "                bias = bias + y[i]\n",
    "                itr = itr + 1\n",
    "                break\n",
    "            else:\n",
    "                error[i] = 0\n",
    "            X1[i] = boundN(w1, bias) + 0.5\n",
    "        plotboundN(X1, y, pp, \"black\", \"Boundary after updating weights\")\n",
    "    plotboundN(X1, y, pp, \"blue\", \"Boundary after perceptron\")\n",
    "    wandb.append([w1, bias])\n",
    "    plt.clf()\n",
    "    print(\"Final number of iterations for the {} PTA: {}\".format(G, itr+1))\n",
    "    print(\"Inital and Final weights & bias for the {} PTA: {}\".format(G, wandb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be31e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs and Expected outputs for AND, OR and NOT gates\n",
    "x = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y_AND = np.array([-1, -1, -1, 1])\n",
    "y_OR = np.array([-1, 1, 1, 1])\n",
    "x_NOT = np.array([0, 1])\n",
    "y_NOT = np.array([1, -1])\n",
    "y_XOR = np.array([-1, 1, 1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86f5c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of iterations for the AND PTA: 12\n",
      "Inital and Final weights & bias for the AND PTA: [[1, 1, 1], [2, 1, -3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train models and create plots for AND - Q1, a & b\n",
    "pp_AND = PdfPages('Iteration_plots_AND.pdf') # Q1, b\n",
    "train(x, y_AND, pp_AND, \"AND\") # Q1, a, i\n",
    "pp_AND.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae26657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of iterations for the OR PTA: 4\n",
      "Inital and Final weights & bias for the OR PTA: [[1, 1, 1], [1, 1, -1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train models and create plots for OR - Q1, a & b\n",
    "pp_OR = PdfPages('Iteration_plots_OR.pdf') # Q1, b\n",
    "train(x, y_OR, pp_OR, \"OR\") # Q1, a, i\n",
    "pp_OR.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3712af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of iterations for the NOT PTA: 5\n",
      "Inital and Final weights & bias for the NOT PTA: [[1, 1], [-1, 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train models and create plots for NOT - Q1, a & b\n",
    "pp_NOT = PdfPages('Iteration_plots_NOT.pdf') # Q1, b\n",
    "trainN(x_NOT, y_NOT, pp_NOT, \"NOT\") # Q1, a, ii\n",
    "pp_NOT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3085bced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuumber of iterations before quiting for the XOR PTA: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train models and create plots for XOR - Q1, c\n",
    "# The perceptron gives up after a few iterations\n",
    "pp_XOR = PdfPages('Iteration_plots_XOR.pdf') # Q1, c\n",
    "train(x, y_XOR, pp_XOR, \"XOR\") # Q1, c\n",
    "pp_XOR.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aade1b",
   "metadata": {},
   "source": [
    "1. c. The number of steps taken to prove that perceptron cannot compute XOR, dsiplayed in the results depends on the number of iterations the conditional loop runs for. The actual number of iterations it took before repeating pattern is 6. It can be seen in the generated plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b6a99",
   "metadata": {},
   "source": [
    "### Implementation of Madeleine learning algorithm for f(x1, x2)\n",
    "#### Points to be noted:\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483542a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
